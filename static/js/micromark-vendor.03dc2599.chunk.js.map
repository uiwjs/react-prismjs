{"version":3,"sources":["../node_modules/micromark/lib/postprocess.js","../node_modules/micromark/lib/preprocess.js","../node_modules/micromark/lib/initialize/content.js","../node_modules/micromark/lib/initialize/document.js","../node_modules/micromark/lib/initialize/flow.js","../node_modules/micromark/lib/initialize/text.js","../node_modules/micromark/lib/create-tokenizer.js","../node_modules/micromark/lib/constructs.js","../node_modules/micromark/lib/parse.js"],"names":["postprocess","events","subtokenize","search","preprocess","atCarriageReturn","column","buffer","start","value","encoding","end","match","next","startPosition","endPosition","code","chunks","toString","charCodeAt","undefined","length","lastIndex","exec","index","slice","push","Math","ceil","content","tokenize","effects","previous","contentStart","attempt","this","parser","constructs","contentInitial","consume","enter","exit","factorySpace","lineStart","token","contentType","data","markdownLineEnding","document","childFlow","childToken","lineStartOffset","self","stack","continued","item","containerState","continuation","documentContinue","checkNewContainers","_closeFlow","closeFlow","point","indexBeforeExits","indexBeforeFlow","type","exitContainers","Object","assign","splice","documentContinued","currentConstruct","concrete","flowStart","interrupt","Boolean","check","containerConstruct","thereIsANewContainer","thereIsNoNewContainer","lazy","now","line","offset","containerContinue","flow","_tokenizer","flowContinue","writeToChild","eof","stream","sliceStream","defineSkip","write","seen","size","entry","call","ok","nok","disable","null","includes","initial","blankLine","flowInitial","afterConstruct","resolver","resolveAll","createResolver","string","initializeFactory","text","field","notText","atBreak","list","resolveAllLineSuffixes","extraResolver","context","eventIndex","bufferIndex","tabs","chunk","_index","_bufferIndex","createTokenizer","initialize","from","columnStart","resolveAllConstructs","accountForPotentialSkip","fields","pop","constructFactory","construct","info","addResult","onsuccessfulcheck","sliceSerialize","expandTabs","atTab","result","String","fromCharCode","join","serializeChunks","main","state","view","startIndex","startBufferIndex","endIndex","endBufferIndex","sliceChunks","chunkIndex","go","_","restore","onreturn","returnState","bogusState","listOfConstructs","constructIndex","Array","isArray","handleListOfConstructs","map","def","all","handleMapOfConstructs","handleConstruct","startPoint","startPrevious","startCurrentConstruct","startEventsIndex","startStack","store","partial","name","create","resolve","resolveTo","blockQuote","definition","codeIndented","headingAtx","thematicBreak","setextUnderline","htmlFlow","codeFenced","characterReference","characterEscape","lineEnding","labelStartImage","attention","autolink","htmlText","labelStartLink","hardBreakEscape","labelEnd","codeText","insideSpan","resolveText","attentionMarkers","parse","options","combineExtensions","defaultConstructs","concat","extensions","defined"],"mappings":"+HAAA,8CASO,SAASA,EAAYC,GAC1B,MAAQC,YAAYD,KAIpB,OAAOA,I,gCCdT,kCAcA,IAAME,EAAS,cAKR,SAASC,IACd,IAOIC,EAPAC,EAAS,EACTC,EAAS,GAGTC,GAAQ,EAIZ,OAGA,SAAsBC,EAAOC,EAAUC,GAErC,IAGIC,EAGAC,EAGAC,EAGAC,EAGAC,EAfEC,EAAS,GAiBfR,EAAQF,EAASE,EAAMS,SAASR,GAChCI,EAAgB,EAChBP,EAAS,GAELC,IAC0B,QAAxBC,EAAMU,WAAW,IACnBL,IAGFN,OAAQY,GAGV,KAAON,EAAgBL,EAAMY,QAAQ,CAOnC,GANAlB,EAAOmB,UAAYR,EACnBF,EAAQT,EAAOoB,KAAKd,GACpBM,EACEH,QAAyBQ,IAAhBR,EAAMY,MAAsBZ,EAAMY,MAAQf,EAAMY,OAC3DL,EAAOP,EAAMU,WAAWJ,IAEnBH,EAAO,CACVL,EAASE,EAAMgB,MAAMX,GACrB,MAGF,GAAa,KAATE,GAAeF,IAAkBC,GAAeV,EAClDY,EAAOS,MAAM,GACbrB,OAAmBe,OAYnB,OAVIf,IACFY,EAAOS,MAAM,GACbrB,OAAmBe,GAGjBN,EAAgBC,IAClBE,EAAOS,KAAKjB,EAAMgB,MAAMX,EAAeC,IACvCT,GAAUS,EAAcD,GAGlBE,GACN,KAAK,EACHC,EAAOS,KAAK,OACZpB,IACA,MAGF,KAAK,EAIH,IAHAO,EAA+B,EAAxBc,KAAKC,KAAKtB,EAAS,GAC1BW,EAAOS,MAAM,GAENpB,IAAWO,GAAMI,EAAOS,MAAM,GAErC,MAGF,KAAK,GACHT,EAAOS,MAAM,GACbpB,EAAS,EACT,MAGF,QACED,GAAmB,EACnBC,EAAS,EAKfQ,EAAgBC,EAAc,EAG5BJ,IACEN,GAAkBY,EAAOS,MAAM,GAC/BnB,GAAQU,EAAOS,KAAKnB,GACxBU,EAAOS,KAAK,OAGd,OAAOT,K,0eCpHEY,EAAU,CACrBC,SAIF,SAA2BC,GACzB,IAOIC,EAPEC,EAAeF,EAAQG,QAC3BC,KAAKC,OAAOC,WAAWC,gBAUzB,SAAoCtB,GAClC,GAAa,OAATA,EAEF,YADAe,EAAQQ,QAAQvB,GAOlB,OAHAe,EAAQS,MAAM,cACdT,EAAQQ,QAAQvB,GAChBe,EAAQU,KAAK,cACNC,YAAaX,EAASE,EAAc,iBAI7C,SAA0BjB,GAExB,OADAe,EAAQS,MAAM,aACPG,EAAU3B,MAlBnB,OAAOiB,EAsBP,SAASU,EAAU3B,GACjB,IAAM4B,EAAQb,EAAQS,MAAM,YAAa,CACvCK,YAAa,OACbb,aAQF,OALIA,IACFA,EAASnB,KAAO+B,GAGlBZ,EAAWY,EACJE,EAAK9B,GAId,SAAS8B,EAAK9B,GACZ,OAAa,OAATA,GACFe,EAAQU,KAAK,aACbV,EAAQU,KAAK,kBACbV,EAAQQ,QAAQvB,IAId+B,YAAmB/B,IACrBe,EAAQQ,QAAQvB,GAChBe,EAAQU,KAAK,aACNE,IAGTZ,EAAQQ,QAAQvB,GACT8B,M,WCxDEE,EAAW,CACtBlB,SASF,SAA4BC,GAC1B,IAOIkB,EAGAC,EAGAC,EAbEC,EAAOjB,KAGPkB,EAAQ,GACVC,EAAY,EAUhB,OAAO9C,EAGP,SAASA,EAAMQ,GAWb,GAAIsC,EAAYD,EAAMhC,OAAQ,CAC5B,IAAMkC,EAAOF,EAAMC,GAEnB,OADAF,EAAKI,eAAiBD,EAAK,GACpBxB,EAAQG,QACbqB,EAAK,GAAGE,aACRC,EACAC,EAHK5B,CAILf,GAGJ,OAAO2C,EAAmB3C,GAI5B,SAAS0C,EAAiB1C,GAKxB,GAJAsC,IAIIF,EAAKI,eAAeI,WAAY,CAClCR,EAAKI,eAAeI,gBAAaxC,EAE7B6B,GACFY,IAUF,IANA,IAIIC,EAJEC,EAAmBX,EAAKnD,OAAOoB,OACjC2C,EAAkBD,EAKfC,KACL,GACsC,SAApCZ,EAAKnD,OAAO+D,GAAiB,IACY,cAAzCZ,EAAKnD,OAAO+D,GAAiB,GAAGC,KAChC,CACAH,EAAQV,EAAKnD,OAAO+D,GAAiB,GAAGrD,IACxC,MAIJuD,EAAeZ,GAIf,IAFA,IAAI9B,EAAQuC,EAELvC,EAAQ4B,EAAKnD,OAAOoB,QACzB+B,EAAKnD,OAAOuB,GAAO,GAAGb,IAAMwD,OAAOC,OAAO,GAAIN,GAC9CtC,IAWF,OARA6C,YACEjB,EAAKnD,OACL+D,EAAkB,EAClB,EACAZ,EAAKnD,OAAOwB,MAAMsC,IAGpBX,EAAKnD,OAAOoB,OAASG,EACdmC,EAAmB3C,GAG5B,OAAOR,EAAMQ,GAIf,SAAS2C,EAAmB3C,GAM1B,GAAIsC,IAAcD,EAAMhC,OAAQ,CAI9B,IAAK4B,EACH,OAAOqB,EAAkBtD,GAK3B,GAAIiC,EAAUsB,kBAAoBtB,EAAUsB,iBAAiBC,SAC3D,OAAOC,EAAUzD,GAKnBoC,EAAKsB,UAAYC,QAAQ1B,EAAUsB,kBAIrC,OADAnB,EAAKI,eAAiB,GACfzB,EAAQ6C,MACbC,EACAC,EACAC,EAHKhD,CAILf,GAIJ,SAAS8D,EAAqB9D,GAG5B,OAFIiC,GAAWY,IACfK,EAAeZ,GACRgB,EAAkBtD,GAI3B,SAAS+D,EAAsB/D,GAG7B,OAFAoC,EAAKhB,OAAO4C,KAAK5B,EAAK6B,MAAMC,MAAQ5B,IAAcD,EAAMhC,OACxD8B,EAAkBC,EAAK6B,MAAME,OACtBV,EAAUzD,GAInB,SAASsD,EAAkBtD,GAGzB,OADAoC,EAAKI,eAAiB,GACfzB,EAAQG,QACb2C,EACAO,EACAX,EAHK1C,CAILf,GAIJ,SAASoE,EAAkBpE,GAIzB,OAHAsC,IACAD,EAAM3B,KAAK,CAAC0B,EAAKmB,iBAAkBnB,EAAKI,iBAEjCc,EAAkBtD,GAI3B,SAASyD,EAAUzD,GACjB,OAAa,OAATA,GACEiC,GAAWY,IACfK,EAAe,QACfnC,EAAQQ,QAAQvB,KAIlBiC,EAAYA,GAAaG,EAAKhB,OAAOiD,KAAKjC,EAAK6B,OAC/ClD,EAAQS,MAAM,YAAa,CACzBK,YAAa,OACbb,SAAUkB,EACVoC,WAAYrC,IAEPsC,EAAavE,IAItB,SAASuE,EAAavE,GACpB,OAAa,OAATA,GACFwE,EAAazD,EAAQU,KAAK,cAAc,GACxCyB,EAAe,QACfnC,EAAQQ,QAAQvB,IAId+B,YAAmB/B,IACrBe,EAAQQ,QAAQvB,GAChBwE,EAAazD,EAAQU,KAAK,cAE1Ba,EAAY,EACZF,EAAKsB,eAAYtD,EACVZ,IAGTuB,EAAQQ,QAAQvB,GACTuE,GAQT,SAASC,EAAa5C,EAAO6C,GAC3B,IAAMC,EAAStC,EAAKuC,YAAY/C,GAwChC,GAvCI6C,GAAKC,EAAOhE,KAAK,MACrBkB,EAAMZ,SAAWkB,EACbA,IAAYA,EAAWrC,KAAO+B,GAClCM,EAAaN,EACbK,EAAU2C,WAAWhD,EAAMpC,OAC3ByC,EAAU4C,MAAMH,GAkCZtC,EAAKhB,OAAO4C,KAAKpC,EAAMpC,MAAM0E,MAAO,CAGtC,IAFA,IAAI1D,EAAQyB,EAAUhD,OAAOoB,OAEtBG,KACL,GAEEyB,EAAUhD,OAAOuB,GAAO,GAAGhB,MAAM2E,OAAShC,KACxCF,EAAUhD,OAAOuB,GAAO,GAAGb,KAC3BsC,EAAUhD,OAAOuB,GAAO,GAAGb,IAAIwE,OAAShC,GAI1C,OAcJ,IATA,IAII2C,EAGAhC,EAPEC,EAAmBX,EAAKnD,OAAOoB,OACjC2C,EAAkBD,EAQfC,KACL,GACsC,SAApCZ,EAAKnD,OAAO+D,GAAiB,IACY,cAAzCZ,EAAKnD,OAAO+D,GAAiB,GAAGC,KAChC,CACA,GAAI6B,EAAM,CACRhC,EAAQV,EAAKnD,OAAO+D,GAAiB,GAAGrD,IACxC,MAGFmF,GAAO,EAQX,IAJA5B,EAAeZ,GAEf9B,EAAQuC,EAEDvC,EAAQ4B,EAAKnD,OAAOoB,QACzB+B,EAAKnD,OAAOuB,GAAO,GAAGb,IAAMwD,OAAOC,OAAO,GAAIN,GAC9CtC,IAGF6C,YACEjB,EAAKnD,OACL+D,EAAkB,EAClB,EACAZ,EAAKnD,OAAOwB,MAAMsC,IAGpBX,EAAKnD,OAAOoB,OAASG,GAQzB,SAAS0C,EAAe6B,GAGtB,IAFA,IAAIvE,EAAQ6B,EAAMhC,OAEXG,KAAUuE,GAAM,CACrB,IAAMC,EAAQ3C,EAAM7B,GACpB4B,EAAKI,eAAiBwC,EAAM,GAC5BA,EAAM,GAAGvD,KAAKwD,KAAK7C,EAAMrB,GAG3BsB,EAAMhC,OAAS0E,EAGjB,SAASlC,IACPZ,EAAU4C,MAAM,CAAC,OACjB3C,OAAa9B,EACb6B,OAAY7B,EACZgC,EAAKI,eAAeI,gBAAaxC,KA7U/ByD,EAAqB,CACzB/C,SAiVF,SAA2BC,EAASmE,EAAIC,GACtC,OAAOzD,YACLX,EACAA,EAAQG,QAAQC,KAAKC,OAAOC,WAAWW,SAAUkD,EAAIC,GACrD,aACAhE,KAAKC,OAAOC,WAAW+D,QAAQC,KAAKC,SAAS,qBAAkBlF,EAAY,K,qBCtWlEiE,EAAO,CAClBvD,SAIF,SAAwBC,GACtB,IAAMqB,EAAOjB,KACPoE,EAAUxE,EAAQG,QAEtBsE,KAmBF,SAAuBxF,GACrB,GAAa,OAATA,EAEF,YADAe,EAAQQ,QAAQvB,GAQlB,OAJAe,EAAQS,MAAM,mBACdT,EAAQQ,QAAQvB,GAChBe,EAAQU,KAAK,mBACbW,EAAKmB,sBAAmBnD,EACjBmF,IA3BPxE,EAAQG,QACNC,KAAKC,OAAOC,WAAWoE,YACvBC,EACAhE,YACEX,EACAA,EAAQG,QACNC,KAAKC,OAAOC,WAAWgD,KACvBqB,EACA3E,EAAQG,QAAQL,IAAS6E,IAE3B,gBAIN,OAAOH,EAiBP,SAASG,EAAe1F,GACtB,GAAa,OAATA,EASJ,OAJAe,EAAQS,MAAM,cACdT,EAAQQ,QAAQvB,GAChBe,EAAQU,KAAK,cACbW,EAAKmB,sBAAmBnD,EACjBmF,EARLxE,EAAQQ,QAAQvB,MC9Cf,IAAM2F,EAAW,CACtBC,WAAYC,KAEDC,EAASC,EAAkB,UAC3BC,EAAOD,EAAkB,QAMtC,SAASA,EAAkBE,GACzB,MAAO,CACLnF,SAOF,SAAwBC,GACtB,IAAMqB,EAAOjB,KACPE,EAAaF,KAAKC,OAAOC,WAAW4E,GACpCD,EAAOjF,EAAQG,QAAQG,EAAY7B,EAAO0G,GAChD,OAAO1G,EAGP,SAASA,EAAMQ,GACb,OAAOmG,EAAQnG,GAAQgG,EAAKhG,GAAQkG,EAAQlG,GAI9C,SAASkG,EAAQlG,GACf,GAAa,OAATA,EAOJ,OAFAe,EAAQS,MAAM,QACdT,EAAQQ,QAAQvB,GACT8B,EANLf,EAAQQ,QAAQvB,GAUpB,SAAS8B,EAAK9B,GACZ,OAAImG,EAAQnG,IACVe,EAAQU,KAAK,QACNuE,EAAKhG,KAGde,EAAQQ,QAAQvB,GACT8B,GAOT,SAASqE,EAAQnG,GACf,GAAa,OAATA,EACF,OAAO,EAGT,IAAMoG,EAAO/E,EAAWrB,GACpBQ,GAAS,EAEb,GAAI4F,EACF,OAAS5F,EAAQ4F,EAAK/F,QAAQ,CAC5B,IAAMkC,EAAO6D,EAAK5F,GAElB,IAAK+B,EAAKvB,UAAYuB,EAAKvB,SAASiE,KAAK7C,EAAMA,EAAKpB,UAClD,OAAO,EAKb,OAAO,IA9DT4E,WAAYC,EACA,SAAVI,EAAmBI,OAAyBjG,IAsElD,SAASyF,EAAeS,GACtB,OAGA,SAAwBrH,EAAQsH,GAC9B,IAGI/E,EAHAhB,GAAS,EAMb,OAASA,GAASvB,EAAOoB,aACTD,IAAVoB,EACEvC,EAAOuB,IAAoC,SAA1BvB,EAAOuB,GAAO,GAAGyC,OACpCzB,EAAQhB,EACRA,KAEQvB,EAAOuB,IAAoC,SAA1BvB,EAAOuB,GAAO,GAAGyC,OAExCzC,IAAUgB,EAAQ,IACpBvC,EAAOuC,GAAO,GAAG7B,IAAMV,EAAOuB,EAAQ,GAAG,GAAGb,IAC5CV,EAAOoE,OAAO7B,EAAQ,EAAGhB,EAAQgB,EAAQ,GACzChB,EAAQgB,EAAQ,GAGlBA,OAAQpB,GAIZ,OAAOkG,EAAgBA,EAAcrH,EAAQsH,GAAWtH,GAe5D,SAASoH,EAAuBpH,EAAQsH,GAGtC,IAFA,IAAIC,GAAc,IAETA,GAAcvH,EAAOoB,QAC5B,IACGmG,IAAevH,EAAOoB,QACU,eAA/BpB,EAAOuH,GAAY,GAAGvD,OACW,SAAnChE,EAAOuH,EAAa,GAAG,GAAGvD,KAC1B,CAUA,IATA,IAAMnB,EAAO7C,EAAOuH,EAAa,GAAG,GAC9BvG,EAASsG,EAAQ5B,YAAY7C,GAC/BtB,EAAQP,EAAOI,OACfoG,GAAe,EACf1B,EAAO,EAGP2B,OAAI,EAEDlG,KAAS,CACd,IAAMmG,EAAQ1G,EAAOO,GAErB,GAAqB,kBAAVmG,EAAoB,CAG7B,IAFAF,EAAcE,EAAMtG,OAEyB,KAAtCsG,EAAMxG,WAAWsG,EAAc,IACpC1B,IACA0B,IAGF,GAAIA,EAAa,MACjBA,GAAe,OAEZ,IAAe,IAAXE,EACPD,GAAO,EACP3B,SACK,IAAe,IAAX4B,EAEJ,CAELnG,IACA,OAIJ,GAAIuE,EAAM,CACR,IAAMnD,EAAQ,CACZqB,KACEuD,IAAevH,EAAOoB,QAAUqG,GAAQ3B,EAAO,EAC3C,aACA,oBACNvF,MAAO,CACL0E,KAAMpC,EAAKnC,IAAIuE,KACf5E,OAAQwC,EAAKnC,IAAIL,OAASyF,EAC1BZ,OAAQrC,EAAKnC,IAAIwE,OAASY,EAC1B6B,OAAQ9E,EAAKtC,MAAMoH,OAASpG,EAC5BqG,aAAcrG,EACViG,EACA3E,EAAKtC,MAAMqH,aAAeJ,GAEhC9G,IAAKwD,OAAOC,OAAO,GAAItB,EAAKnC,MAE9BmC,EAAKnC,IAAMwD,OAAOC,OAAO,GAAIxB,EAAMpC,OAE/BsC,EAAKtC,MAAM2E,SAAWrC,EAAKnC,IAAIwE,OACjChB,OAAOC,OAAOtB,EAAMF,IAEpB3C,EAAOoE,OACLmD,EACA,EACA,CAAC,QAAS5E,EAAO2E,GACjB,CAAC,OAAQ3E,EAAO2E,IAElBC,GAAc,GAIlBA,IAIJ,OAAOvH,E,mBC7KF,SAAS6H,EAAgB1F,EAAQ2F,EAAYC,GAElD,IAAIlE,EAAQK,OAAOC,OACjB4D,EACI7D,OAAOC,OAAO,GAAI4D,GAClB,CACE9C,KAAM,EACN5E,OAAQ,EACR6E,OAAQ,GAEd,CACEyC,OAAQ,EACRC,cAAe,IAKbI,EAAc,GAGdC,EAAuB,GAGzBjH,EAAS,GAGToC,EAAQ,GAUNtB,EAAU,CACdQ,QA2IF,SAAiBvB,GACX+B,YAAmB/B,IACrB8C,EAAMoB,OACNpB,EAAMxD,OAAS,EACfwD,EAAMqB,SAAoB,IAAVnE,EAAc,EAAI,EAClCmH,MACmB,IAAVnH,IACT8C,EAAMxD,SACNwD,EAAMqB,UAGJrB,EAAM+D,aAAe,EACvB/D,EAAM8D,UAEN9D,EAAM+D,eAIF/D,EAAM+D,eAAiB5G,EAAO6C,EAAM8D,QAAQvG,SAC9CyC,EAAM+D,cAAgB,EACtB/D,EAAM8D,WAIVL,EAAQvF,SAAWhB,GAER,GApKXwB,MAwKF,SAAeyB,EAAMmE,GAGnB,IAAMxF,EAAQwF,GAAU,GAKxB,OAJAxF,EAAMqB,KAAOA,EACbrB,EAAMpC,MAAQyE,IACdsC,EAAQtH,OAAOyB,KAAK,CAAC,QAASkB,EAAO2E,IACrClE,EAAM3B,KAAKkB,GACJA,GA/KPH,KAmLF,SAAcwB,GACZ,IAAMrB,EAAQS,EAAMgF,MAGpB,OAFAzF,EAAMjC,IAAMsE,IACZsC,EAAQtH,OAAOyB,KAAK,CAAC,OAAQkB,EAAO2E,IAC7B3E,GAtLPV,QAASoG,GA8LX,SAA+BC,EAAWC,GACxCC,EAAUF,EAAWC,EAAKR,SA9L1BpD,MAAO0D,EAAiBI,GACxBhE,UAAW4D,EAAiBI,EAAmB,CAC7ChE,WAAW,KAST6C,EAAU,CACdvF,SAAU,KACVhB,KAAM,KACNwC,eAAgB,GAChBvD,OAAQ,GACRmC,SACAuD,cACAgD,eA6CF,SAAwB/F,EAAOgG,GAC7B,OAsYJ,SAAyB3H,EAAQ2H,GAC/B,IAMIC,EANArH,GAAS,EAGPsH,EAAS,GAKf,OAAStH,EAAQP,EAAOI,QAAQ,CAC9B,IAAMsG,EAAQ1G,EAAOO,GAGjBf,OAAK,EAET,GAAqB,kBAAVkH,EACTlH,EAAQkH,OAER,OAAQA,GACN,KAAM,EACJlH,EAAQ,KACR,MAGF,KAAM,EACJA,EAAQ,KACR,MAGF,KAAM,EACJA,EAAQ,OACR,MAGF,KAAM,EACJA,EAAQmI,EAAa,IAAM,KAC3B,MAGF,KAAM,EACJ,IAAKA,GAAcC,EAAO,SAC1BpI,EAAQ,IACR,MAGF,QAEEA,EAAQsI,OAAOC,aAAarB,GAIlCkB,GAAmB,IAAXlB,EACRmB,EAAOpH,KAAKjB,GAGd,OAAOqI,EAAOG,KAAK,IA7bVC,CAAgBvD,EAAY/C,GAAQgG,IA7C3C3D,MACAW,WA0DF,SAAoBnF,GAClBwH,EAAYxH,EAAMyE,MAAQzE,EAAMH,OAChC6H,KA3DAtC,MAwBF,SAAepE,GAIb,GAHAR,EAASS,YAAKT,EAAQQ,GACtB0H,IAEkC,OAA9BlI,EAAOA,EAAOI,OAAS,GACzB,MAAO,GAMT,OAHAoH,EAAUV,EAAY,GAEtBR,EAAQtH,OAAS2G,YAAWsB,EAAsBX,EAAQtH,OAAQsH,GAC3DA,EAAQtH,SA3BbmJ,EAAQrB,EAAWjG,SAASmE,KAAKsB,EAASxF,GAa9C,OAJIgG,EAAWnB,YACbsB,EAAqBxG,KAAKqG,GAGrBR,EA0BP,SAAS5B,EAAY/C,GACnB,OA6VJ,SAAqB3B,EAAQ2B,GAC3B,IAMIyG,EANEC,EAAa1G,EAAMpC,MAAMoH,OACzB2B,EAAmB3G,EAAMpC,MAAMqH,aAC/B2B,EAAW5G,EAAMjC,IAAIiH,OACrB6B,EAAiB7G,EAAMjC,IAAIkH,aAK7ByB,IAAeE,EAEjBH,EAAO,CAACpI,EAAOqI,GAAY7H,MAAM8H,EAAkBE,KAEnDJ,EAAOpI,EAAOQ,MAAM6H,EAAYE,GAE5BD,GAAoB,IAEtBF,EAAK,GAAKA,EAAK,GAAG5H,MAAM8H,IAGtBE,EAAiB,GAEnBJ,EAAK3H,KAAKT,EAAOuI,GAAU/H,MAAM,EAAGgI,KAIxC,OAAOJ,EAvXEK,CAAYzI,EAAQ2B,GAI7B,SAASqC,IACP,OAAOd,OAAOC,OAAO,GAAIN,GAsB3B,SAASqF,IAIP,IAFA,IAAIQ,EAEG7F,EAAM8D,OAAS3G,EAAOI,QAAQ,CACnC,IAAMsG,EAAQ1G,EAAO6C,EAAM8D,QAE3B,GAAqB,kBAAVD,EAOT,IANAgC,EAAa7F,EAAM8D,OAEf9D,EAAM+D,aAAe,IACvB/D,EAAM+D,aAAe,GAIrB/D,EAAM8D,SAAW+B,GACjB7F,EAAM+D,aAAeF,EAAMtG,QAE3BuI,EAAGjC,EAAMxG,WAAW2C,EAAM+D,oBAG5B+B,EAAGjC,IAWT,SAASiC,EAAG5I,QACCI,EACIJ,EACfoI,EAAQA,EAAMpI,GAmEhB,SAAS0H,EAAkBmB,EAAGrB,GAC5BA,EAAKsB,UASP,SAASxB,EAAiByB,EAAU3B,GAClC,OAWA,SAAc/F,EAAY2H,EAAaC,GAErC,IAAIC,EAGAC,EAGA5F,EAGAiE,EACJ,OAAO4B,MAAMC,QAAQhI,GAEjBiI,EAAuBjI,GACvB,aAAcA,EACdiI,EAAuB,CAACjI,IAS5B,SAA+BkI,GAC7B,OAAO/J,EAGP,SAASA,EAAMQ,GACb,IAAMwJ,EAAe,OAATxJ,GAAiBuJ,EAAIvJ,GAC3ByJ,EAAe,OAATzJ,GAAiBuJ,EAAIlE,KAQjC,OAAOiE,EAPM,GAAH,mBAIJF,MAAMC,QAAQG,GAAOA,EAAMA,EAAM,CAACA,GAAO,IAJrC,YAKJJ,MAAMC,QAAQI,GAAOA,EAAMA,EAAM,CAACA,GAAO,KAExCH,CAA6BtJ,IAtBpC0J,CAAsBrI,GAgC1B,SAASiI,EAAuBlD,GAI9B,OAHA8C,EAAmB9C,EACnB+C,EAAiB,EAEG,IAAhB/C,EAAK/F,OACA4I,EAGFU,EAAgBvD,EAAK+C,IAS9B,SAASQ,EAAgBpC,GACvB,OAGA,SAAevH,GAKbwH,EA4ER,WACE,IAAMoC,EAAa3F,IACb4F,EAAgBtD,EAAQvF,SACxB8I,EAAwBvD,EAAQhD,iBAChCwG,EAAmBxD,EAAQtH,OAAOoB,OAClC2J,EAAaZ,MAAMpC,KAAK3E,GAC9B,MAAO,CACLyG,UACA9B,KAAM+C,GAQR,SAASjB,IACPhG,EAAQ8G,EACRrD,EAAQvF,SAAW6I,EACnBtD,EAAQhD,iBAAmBuG,EAC3BvD,EAAQtH,OAAOoB,OAAS0J,EACxB1H,EAAQ2H,EACR7C,KAlGW8C,GACP1G,EAAmBgE,EAEdA,EAAU2C,UACb3D,EAAQhD,iBAAmBgE,GAG7B,GACEA,EAAU4C,MACV5D,EAAQnF,OAAOC,WAAW+D,QAAQC,KAAKC,SAASiC,EAAU4C,MAE1D,OAAOhF,EAAInF,GAGb,OAAOuH,EAAUzG,SAASmE,KAIxBmC,EAASjE,OAAOC,OAAOD,OAAOiH,OAAO7D,GAAUa,GAAUb,EACzDxF,EACAmE,EACAC,EAPKoC,CAQLvH,IAKN,SAASkF,EAAGlF,GAGV,OAFW,EACX+I,EAASxF,EAAkBiE,GACpBwB,EAIT,SAAS7D,EAAInF,GAIX,OAHW,EACXwH,EAAKsB,YAECK,EAAiBD,EAAiB7I,OAC/BsJ,EAAgBT,EAAiBC,IAGnCF,IAUb,SAASxB,EAAUF,EAAWP,GACxBO,EAAU3B,aAAesB,EAAqB5B,SAASiC,IACzDL,EAAqBxG,KAAK6G,GAGxBA,EAAU8C,SACZhH,YACEkD,EAAQtH,OACR+H,EACAT,EAAQtH,OAAOoB,OAAS2G,EACxBO,EAAU8C,QAAQ9D,EAAQtH,OAAOwB,MAAMuG,GAAOT,IAI9CgB,EAAU+C,YACZ/D,EAAQtH,OAASsI,EAAU+C,UAAU/D,EAAQtH,OAAQsH,IAyCzD,SAASY,IACHrE,EAAMoB,QAAQ+C,GAAenE,EAAMxD,OAAS,IAC9CwD,EAAMxD,OAAS2H,EAAYnE,EAAMoB,MACjCpB,EAAMqB,QAAU8C,EAAYnE,EAAMoB,MAAQ,I,uMC9cnClC,GAAQ,mBAClB,GAAKoE,KADa,cAElB,GAAKA,KAFa,cAGlB,GAAKA,KAHa,cAIlB,GAAKA,KAJa,cAKlB,GAAKA,KALa,cAMlB,GAAKA,KANa,cAOlB,GAAKA,KAPa,cAQlB,GAAKA,KARa,cASlB,GAAKA,KATa,cAUlB,GAAKA,KAVa,cAWlB,GAAKA,KAXa,cAYlB,GAAKA,KAZa,cAalB,GAAKA,KAba,cAclB,GAAKmE,KAda,GAkBRjJ,EAAiB,eAC3B,GAAKkJ,KAIK/E,GAAW,oBACpB,EAAIgF,KADgB,eAEpB,EAAIA,KAFgB,cAGrB,GAAKA,KAHgB,GAOXpG,GAAI,mBACd,GAAKqG,KADS,cAEd,GAAKC,KAFS,cAGd,GAAK,CAACC,IAAiBD,MAHT,cAId,GAAKE,KAJS,cAKd,GAAKD,KALS,cAMd,GAAKD,KANS,cAOd,GAAKG,KAPS,cAQd,IAAMA,KARQ,GAYJhF,GAAM,mBAChB,GAAKiF,KADW,cAEhB,GAAKC,KAFW,GAMNhF,IAAI,oBACb,EAAIiF,KADS,eAEb,EAAIA,KAFS,eAGb,EAAIA,KAHS,cAId,GAAKC,KAJS,cAKd,GAAKH,KALS,cAMd,GAAKI,KANS,cAOd,GAAK,CAACC,IAAUC,MAPF,cAQd,GAAKC,KARS,cASd,GAAK,CAACC,IAAiBP,MATT,cAUd,GAAKQ,KAVS,cAWd,GAAKL,KAXS,cAYd,GAAKM,KAZS,GAgBJC,GAAa,CACxBrG,KAAM,CAAC8F,IAAWQ,IAIPC,GAAmB,CAC9BvG,KAAM,CAAC,GAAI,KAIAD,GAAU,CACrBC,KAAM,ICpFD,SAASwG,KAAoB,IAAdC,EAAc,uDAAJ,GAGxBzK,EAAa0K,YAEjB,CAACC,GAAmBC,OAAOH,EAAQI,YAAc,KAI7C9K,EAAS,CACb+K,QAAS,GACTnI,KAAM,GACN3C,aACAR,QAASuJ,EAAOvJ,GAChBmB,SAAUoI,EAAOpI,GACjBqC,KAAM+F,EAAO/F,GACbyB,OAAQsE,EAAOtE,GACfE,KAAMoE,EAAOpE,IAEf,OAAO5E,EAKP,SAASgJ,EAAO7E,GACd,OAGA,SAAiByB,GACf,OAAOF,EAAgB1F,EAAQmE,EAASyB","file":"static/js/micromark-vendor.03dc2599.chunk.js","sourcesContent":["/**\n * @typedef {import('micromark-util-types').Event} Event\n */\nimport {subtokenize} from 'micromark-util-subtokenize'\n/**\n * @param {Event[]} events\n * @returns {Event[]}\n */\n\nexport function postprocess(events) {\n  while (!subtokenize(events)) {\n    // Empty\n  }\n\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Encoding} Encoding\n * @typedef {import('micromark-util-types').Value} Value\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Code} Code\n */\n\n/**\n * @callback Preprocessor\n * @param {Value} value\n * @param {Encoding} [encoding]\n * @param {boolean} [end=false]\n * @returns {Chunk[]}\n */\nconst search = /[\\0\\t\\n\\r]/g\n/**\n * @returns {Preprocessor}\n */\n\nexport function preprocess() {\n  let column = 1\n  let buffer = ''\n  /** @type {boolean|undefined} */\n\n  let start = true\n  /** @type {boolean|undefined} */\n\n  let atCarriageReturn\n  return preprocessor\n  /** @type {Preprocessor} */\n\n  function preprocessor(value, encoding, end) {\n    /** @type {Chunk[]} */\n    const chunks = []\n    /** @type {RegExpMatchArray|null} */\n\n    let match\n    /** @type {number} */\n\n    let next\n    /** @type {number} */\n\n    let startPosition\n    /** @type {number} */\n\n    let endPosition\n    /** @type {Code} */\n\n    let code // @ts-expect-error `Buffer` does allow an encoding.\n\n    value = buffer + value.toString(encoding)\n    startPosition = 0\n    buffer = ''\n\n    if (start) {\n      if (value.charCodeAt(0) === 65279) {\n        startPosition++\n      }\n\n      start = undefined\n    }\n\n    while (startPosition < value.length) {\n      search.lastIndex = startPosition\n      match = search.exec(value)\n      endPosition =\n        match && match.index !== undefined ? match.index : value.length\n      code = value.charCodeAt(endPosition)\n\n      if (!match) {\n        buffer = value.slice(startPosition)\n        break\n      }\n\n      if (code === 10 && startPosition === endPosition && atCarriageReturn) {\n        chunks.push(-3)\n        atCarriageReturn = undefined\n      } else {\n        if (atCarriageReturn) {\n          chunks.push(-5)\n          atCarriageReturn = undefined\n        }\n\n        if (startPosition < endPosition) {\n          chunks.push(value.slice(startPosition, endPosition))\n          column += endPosition - startPosition\n        }\n\n        switch (code) {\n          case 0: {\n            chunks.push(65533)\n            column++\n            break\n          }\n\n          case 9: {\n            next = Math.ceil(column / 4) * 4\n            chunks.push(-2)\n\n            while (column++ < next) chunks.push(-1)\n\n            break\n          }\n\n          case 10: {\n            chunks.push(-4)\n            column = 1\n            break\n          }\n\n          default: {\n            atCarriageReturn = true\n            column = 1\n          }\n        }\n      }\n\n      startPosition = endPosition + 1\n    }\n\n    if (end) {\n      if (atCarriageReturn) chunks.push(-5)\n      if (buffer) chunks.push(buffer)\n      chunks.push(null)\n    }\n\n    return chunks\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n\n/** @type {InitialConstruct} */\nexport const content = {\n  tokenize: initializeContent\n}\n/** @type {Initializer} */\n\nfunction initializeContent(effects) {\n  const contentStart = effects.attempt(\n    this.parser.constructs.contentInitial,\n    afterContentStartConstruct,\n    paragraphInitial\n  )\n  /** @type {Token} */\n\n  let previous\n  return contentStart\n  /** @type {State} */\n\n  function afterContentStartConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    return factorySpace(effects, contentStart, 'linePrefix')\n  }\n  /** @type {State} */\n\n  function paragraphInitial(code) {\n    effects.enter('paragraph')\n    return lineStart(code)\n  }\n  /** @type {State} */\n\n  function lineStart(code) {\n    const token = effects.enter('chunkText', {\n      contentType: 'text',\n      previous\n    })\n\n    if (previous) {\n      previous.next = token\n    }\n\n    previous = token\n    return data(code)\n  }\n  /** @type {State} */\n\n  function data(code) {\n    if (code === null) {\n      effects.exit('chunkText')\n      effects.exit('paragraph')\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      effects.exit('chunkText')\n      return lineStart\n    } // Data.\n\n    effects.consume(code)\n    return data\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Point} Point\n */\n\n/**\n * @typedef {Record<string, unknown>} StackState\n * @typedef {[Construct, StackState]} StackItem\n */\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {splice} from 'micromark-util-chunked'\n/** @type {InitialConstruct} */\n\nexport const document = {\n  tokenize: initializeDocument\n}\n/** @type {Construct} */\n\nconst containerConstruct = {\n  tokenize: tokenizeContainer\n}\n/** @type {Initializer} */\n\nfunction initializeDocument(effects) {\n  const self = this\n  /** @type {StackItem[]} */\n\n  const stack = []\n  let continued = 0\n  /** @type {TokenizeContext|undefined} */\n\n  let childFlow\n  /** @type {Token|undefined} */\n\n  let childToken\n  /** @type {number} */\n\n  let lineStartOffset\n  return start\n  /** @type {State} */\n\n  function start(code) {\n    // First we iterate through the open blocks, starting with the root\n    // document, and descending through last children down to the last open\n    // block.\n    // Each block imposes a condition that the line must satisfy if the block is\n    // to remain open.\n    // For example, a block quote requires a `>` character.\n    // A paragraph requires a non-blank line.\n    // In this phase we may match all or just some of the open blocks.\n    // But we cannot close unmatched blocks yet, because we may have a lazy\n    // continuation line.\n    if (continued < stack.length) {\n      const item = stack[continued]\n      self.containerState = item[1]\n      return effects.attempt(\n        item[0].continuation,\n        documentContinue,\n        checkNewContainers\n      )(code)\n    } // Done.\n\n    return checkNewContainers(code)\n  }\n  /** @type {State} */\n\n  function documentContinue(code) {\n    continued++ // Note: this field is called `_closeFlow` but it also closes containers.\n    // Perhaps a good idea to rename it but it’s already used in the wild by\n    // extensions.\n\n    if (self.containerState._closeFlow) {\n      self.containerState._closeFlow = undefined\n\n      if (childFlow) {\n        closeFlow()\n      } // Note: this algorithm for moving events around is similar to the\n      // algorithm when dealing with lazy lines in `writeToChild`.\n\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {Point|undefined} */\n\n      let point // Find the flow chunk.\n\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          point = self.events[indexBeforeFlow][1].end\n          break\n        }\n      }\n\n      exitContainers(continued) // Fix positions.\n\n      let index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      } // Inject the exits earlier (they’re still also at the end).\n\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      ) // Discard the duplicate exits.\n\n      self.events.length = index\n      return checkNewContainers(code)\n    }\n\n    return start(code)\n  }\n  /** @type {State} */\n\n  function checkNewContainers(code) {\n    // Next, after consuming the continuation markers for existing blocks, we\n    // look for new block starts (e.g. `>` for a block quote).\n    // If we encounter a new block start, we close any blocks unmatched in\n    // step 1 before creating the new block as a child of the last matched\n    // block.\n    if (continued === stack.length) {\n      // No need to `check` whether there’s a container, of `exitContainers`\n      // would be moot.\n      // We can instead immediately `attempt` to parse one.\n      if (!childFlow) {\n        return documentContinued(code)\n      } // If we have concrete content, such as block HTML or fenced code,\n      // we can’t have containers “pierce” into them, so we can immediately\n      // start.\n\n      if (childFlow.currentConstruct && childFlow.currentConstruct.concrete) {\n        return flowStart(code)\n      } // If we do have flow, it could still be a blank line,\n      // but we’d be interrupting it w/ a new container if there’s a current\n      // construct.\n\n      self.interrupt = Boolean(childFlow.currentConstruct)\n    } // Check if there is a new container.\n\n    self.containerState = {}\n    return effects.check(\n      containerConstruct,\n      thereIsANewContainer,\n      thereIsNoNewContainer\n    )(code)\n  }\n  /** @type {State} */\n\n  function thereIsANewContainer(code) {\n    if (childFlow) closeFlow()\n    exitContainers(continued)\n    return documentContinued(code)\n  }\n  /** @type {State} */\n\n  function thereIsNoNewContainer(code) {\n    self.parser.lazy[self.now().line] = continued !== stack.length\n    lineStartOffset = self.now().offset\n    return flowStart(code)\n  }\n  /** @type {State} */\n\n  function documentContinued(code) {\n    // Try new containers.\n    self.containerState = {}\n    return effects.attempt(\n      containerConstruct,\n      containerContinue,\n      flowStart\n    )(code)\n  }\n  /** @type {State} */\n\n  function containerContinue(code) {\n    continued++\n    stack.push([self.currentConstruct, self.containerState]) // Try another.\n\n    return documentContinued(code)\n  }\n  /** @type {State} */\n\n  function flowStart(code) {\n    if (code === null) {\n      if (childFlow) closeFlow()\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    childFlow = childFlow || self.parser.flow(self.now())\n    effects.enter('chunkFlow', {\n      contentType: 'flow',\n      previous: childToken,\n      _tokenizer: childFlow\n    })\n    return flowContinue(code)\n  }\n  /** @type {State} */\n\n  function flowContinue(code) {\n    if (code === null) {\n      writeToChild(effects.exit('chunkFlow'), true)\n      exitContainers(0)\n      effects.consume(code)\n      return\n    }\n\n    if (markdownLineEnding(code)) {\n      effects.consume(code)\n      writeToChild(effects.exit('chunkFlow')) // Get ready for the next line.\n\n      continued = 0\n      self.interrupt = undefined\n      return start\n    }\n\n    effects.consume(code)\n    return flowContinue\n  }\n  /**\n   * @param {Token} token\n   * @param {boolean} [eof]\n   * @returns {void}\n   */\n\n  function writeToChild(token, eof) {\n    const stream = self.sliceStream(token)\n    if (eof) stream.push(null)\n    token.previous = childToken\n    if (childToken) childToken.next = token\n    childToken = token\n    childFlow.defineSkip(token.start)\n    childFlow.write(stream) // Alright, so we just added a lazy line:\n    //\n    // ```markdown\n    // > a\n    // b.\n    //\n    // Or:\n    //\n    // > ~~~c\n    // d\n    //\n    // Or:\n    //\n    // > | e |\n    // f\n    // ```\n    //\n    // The construct in the second example (fenced code) does not accept lazy\n    // lines, so it marked itself as done at the end of its first line, and\n    // then the content construct parses `d`.\n    // Most constructs in markdown match on the first line: if the first line\n    // forms a construct, a non-lazy line can’t “unmake” it.\n    //\n    // The construct in the third example is potentially a GFM table, and\n    // those are *weird*.\n    // It *could* be a table, from the first line, if the following line\n    // matches a condition.\n    // In this case, that second line is lazy, which “unmakes” the first line\n    // and turns the whole into one content block.\n    //\n    // We’ve now parsed the non-lazy and the lazy line, and can figure out\n    // whether the lazy line started a new flow block.\n    // If it did, we exit the current containers between the two flow blocks.\n\n    if (self.parser.lazy[token.start.line]) {\n      let index = childFlow.events.length\n\n      while (index--) {\n        if (\n          // The token starts before the line ending…\n          childFlow.events[index][1].start.offset < lineStartOffset &&\n          (!childFlow.events[index][1].end || // …or ends after it.\n            childFlow.events[index][1].end.offset > lineStartOffset)\n        ) {\n          // Exit: there’s still something open, which means it’s a lazy line\n          // part of something.\n          return\n        }\n      } // Note: this algorithm for moving events around is similar to the\n      // algorithm when closing flow in `documentContinue`.\n\n      const indexBeforeExits = self.events.length\n      let indexBeforeFlow = indexBeforeExits\n      /** @type {boolean|undefined} */\n\n      let seen\n      /** @type {Point|undefined} */\n\n      let point // Find the previous chunk (the one before the lazy line).\n\n      while (indexBeforeFlow--) {\n        if (\n          self.events[indexBeforeFlow][0] === 'exit' &&\n          self.events[indexBeforeFlow][1].type === 'chunkFlow'\n        ) {\n          if (seen) {\n            point = self.events[indexBeforeFlow][1].end\n            break\n          }\n\n          seen = true\n        }\n      }\n\n      exitContainers(continued) // Fix positions.\n\n      index = indexBeforeExits\n\n      while (index < self.events.length) {\n        self.events[index][1].end = Object.assign({}, point)\n        index++\n      } // Inject the exits earlier (they’re still also at the end).\n\n      splice(\n        self.events,\n        indexBeforeFlow + 1,\n        0,\n        self.events.slice(indexBeforeExits)\n      ) // Discard the duplicate exits.\n\n      self.events.length = index\n    }\n  }\n  /**\n   * @param {number} size\n   * @returns {void}\n   */\n\n  function exitContainers(size) {\n    let index = stack.length // Exit open containers.\n\n    while (index-- > size) {\n      const entry = stack[index]\n      self.containerState = entry[1]\n      entry[0].exit.call(self, effects)\n    }\n\n    stack.length = size\n  }\n\n  function closeFlow() {\n    childFlow.write([null])\n    childToken = undefined\n    childFlow = undefined\n    self.containerState._closeFlow = undefined\n  }\n}\n/** @type {Tokenizer} */\n\nfunction tokenizeContainer(effects, ok, nok) {\n  return factorySpace(\n    effects,\n    effects.attempt(this.parser.constructs.document, ok, nok),\n    'linePrefix',\n    this.parser.constructs.disable.null.includes('codeIndented') ? undefined : 4\n  )\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').State} State\n */\nimport {blankLine, content} from 'micromark-core-commonmark'\nimport {factorySpace} from 'micromark-factory-space'\nimport {markdownLineEnding} from 'micromark-util-character'\n\n/** @type {InitialConstruct} */\nexport const flow = {\n  tokenize: initializeFlow\n}\n/** @type {Initializer} */\n\nfunction initializeFlow(effects) {\n  const self = this\n  const initial = effects.attempt(\n    // Try to parse a blank line.\n    blankLine,\n    atBlankEnding, // Try to parse initial flow (essentially, only code).\n    effects.attempt(\n      this.parser.constructs.flowInitial,\n      afterConstruct,\n      factorySpace(\n        effects,\n        effects.attempt(\n          this.parser.constructs.flow,\n          afterConstruct,\n          effects.attempt(content, afterConstruct)\n        ),\n        'linePrefix'\n      )\n    )\n  )\n  return initial\n  /** @type {State} */\n\n  function atBlankEnding(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEndingBlank')\n    effects.consume(code)\n    effects.exit('lineEndingBlank')\n    self.currentConstruct = undefined\n    return initial\n  }\n  /** @type {State} */\n\n  function afterConstruct(code) {\n    if (code === null) {\n      effects.consume(code)\n      return\n    }\n\n    effects.enter('lineEnding')\n    effects.consume(code)\n    effects.exit('lineEnding')\n    self.currentConstruct = undefined\n    return initial\n  }\n}\n","/**\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').Initializer} Initializer\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Code} Code\n */\nexport const resolver = {\n  resolveAll: createResolver()\n}\nexport const string = initializeFactory('string')\nexport const text = initializeFactory('text')\n/**\n * @param {'string'|'text'} field\n * @returns {InitialConstruct}\n */\n\nfunction initializeFactory(field) {\n  return {\n    tokenize: initializeText,\n    resolveAll: createResolver(\n      field === 'text' ? resolveAllLineSuffixes : undefined\n    )\n  }\n  /** @type {Initializer} */\n\n  function initializeText(effects) {\n    const self = this\n    const constructs = this.parser.constructs[field]\n    const text = effects.attempt(constructs, start, notText)\n    return start\n    /** @type {State} */\n\n    function start(code) {\n      return atBreak(code) ? text(code) : notText(code)\n    }\n    /** @type {State} */\n\n    function notText(code) {\n      if (code === null) {\n        effects.consume(code)\n        return\n      }\n\n      effects.enter('data')\n      effects.consume(code)\n      return data\n    }\n    /** @type {State} */\n\n    function data(code) {\n      if (atBreak(code)) {\n        effects.exit('data')\n        return text(code)\n      } // Data.\n\n      effects.consume(code)\n      return data\n    }\n    /**\n     * @param {Code} code\n     * @returns {boolean}\n     */\n\n    function atBreak(code) {\n      if (code === null) {\n        return true\n      }\n\n      const list = constructs[code]\n      let index = -1\n\n      if (list) {\n        while (++index < list.length) {\n          const item = list[index]\n\n          if (!item.previous || item.previous.call(self, self.previous)) {\n            return true\n          }\n        }\n      }\n\n      return false\n    }\n  }\n}\n/**\n * @param {Resolver} [extraResolver]\n * @returns {Resolver}\n */\n\nfunction createResolver(extraResolver) {\n  return resolveAllText\n  /** @type {Resolver} */\n\n  function resolveAllText(events, context) {\n    let index = -1\n    /** @type {number|undefined} */\n\n    let enter // A rather boring computation (to merge adjacent `data` events) which\n    // improves mm performance by 29%.\n\n    while (++index <= events.length) {\n      if (enter === undefined) {\n        if (events[index] && events[index][1].type === 'data') {\n          enter = index\n          index++\n        }\n      } else if (!events[index] || events[index][1].type !== 'data') {\n        // Don’t do anything if there is one data token.\n        if (index !== enter + 2) {\n          events[enter][1].end = events[index - 1][1].end\n          events.splice(enter + 2, index - enter - 2)\n          index = enter + 2\n        }\n\n        enter = undefined\n      }\n    }\n\n    return extraResolver ? extraResolver(events, context) : events\n  }\n}\n/**\n * A rather ugly set of instructions which again looks at chunks in the input\n * stream.\n * The reason to do this here is that it is *much* faster to parse in reverse.\n * And that we can’t hook into `null` to split the line suffix before an EOF.\n * To do: figure out if we can make this into a clean utility, or even in core.\n * As it will be useful for GFMs literal autolink extension (and maybe even\n * tables?)\n *\n * @type {Resolver}\n */\n\nfunction resolveAllLineSuffixes(events, context) {\n  let eventIndex = -1\n\n  while (++eventIndex <= events.length) {\n    if (\n      (eventIndex === events.length ||\n        events[eventIndex][1].type === 'lineEnding') &&\n      events[eventIndex - 1][1].type === 'data'\n    ) {\n      const data = events[eventIndex - 1][1]\n      const chunks = context.sliceStream(data)\n      let index = chunks.length\n      let bufferIndex = -1\n      let size = 0\n      /** @type {boolean|undefined} */\n\n      let tabs\n\n      while (index--) {\n        const chunk = chunks[index]\n\n        if (typeof chunk === 'string') {\n          bufferIndex = chunk.length\n\n          while (chunk.charCodeAt(bufferIndex - 1) === 32) {\n            size++\n            bufferIndex--\n          }\n\n          if (bufferIndex) break\n          bufferIndex = -1\n        } // Number\n        else if (chunk === -2) {\n          tabs = true\n          size++\n        } else if (chunk === -1) {\n          // Empty\n        } else {\n          // Replacement character, exit.\n          index++\n          break\n        }\n      }\n\n      if (size) {\n        const token = {\n          type:\n            eventIndex === events.length || tabs || size < 2\n              ? 'lineSuffix'\n              : 'hardBreakTrailing',\n          start: {\n            line: data.end.line,\n            column: data.end.column - size,\n            offset: data.end.offset - size,\n            _index: data.start._index + index,\n            _bufferIndex: index\n              ? bufferIndex\n              : data.start._bufferIndex + bufferIndex\n          },\n          end: Object.assign({}, data.end)\n        }\n        data.end = Object.assign({}, token.start)\n\n        if (data.start.offset === data.end.offset) {\n          Object.assign(data, token)\n        } else {\n          events.splice(\n            eventIndex,\n            0,\n            ['enter', token, context],\n            ['exit', token, context]\n          )\n          eventIndex += 2\n        }\n      }\n\n      eventIndex++\n    }\n  }\n\n  return events\n}\n","/**\n * @typedef {import('micromark-util-types').Code} Code\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Point} Point\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').Effects} Effects\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').ConstructRecord} ConstructRecord\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n */\n\n/**\n * @typedef Info\n * @property {() => void} restore\n * @property {number} from\n *\n * @callback ReturnHandle\n *   Handle a successful run.\n * @param {Construct} construct\n * @param {Info} info\n * @returns {void}\n */\nimport {markdownLineEnding} from 'micromark-util-character'\nimport {push, splice} from 'micromark-util-chunked'\nimport {resolveAll} from 'micromark-util-resolve-all'\n\n/**\n * Create a tokenizer.\n * Tokenizers deal with one type of data (e.g., containers, flow, text).\n * The parser is the object dealing with it all.\n * `initialize` works like other constructs, except that only its `tokenize`\n * function is used, in which case it doesn’t receive an `ok` or `nok`.\n * `from` can be given to set the point before the first character, although\n * when further lines are indented, they must be set with `defineSkip`.\n *\n * @param {ParseContext} parser\n * @param {InitialConstruct} initialize\n * @param {Omit<Point, '_index'|'_bufferIndex'>} [from]\n * @returns {TokenizeContext}\n */\nexport function createTokenizer(parser, initialize, from) {\n  /** @type {Point} */\n  let point = Object.assign(\n    from\n      ? Object.assign({}, from)\n      : {\n          line: 1,\n          column: 1,\n          offset: 0\n        },\n    {\n      _index: 0,\n      _bufferIndex: -1\n    }\n  )\n  /** @type {Record<string, number>} */\n\n  const columnStart = {}\n  /** @type {Construct[]} */\n\n  const resolveAllConstructs = []\n  /** @type {Chunk[]} */\n\n  let chunks = []\n  /** @type {Token[]} */\n\n  let stack = []\n  /** @type {boolean|undefined} */\n\n  let consumed = true\n  /**\n   * Tools used for tokenizing.\n   *\n   * @type {Effects}\n   */\n\n  const effects = {\n    consume,\n    enter,\n    exit,\n    attempt: constructFactory(onsuccessfulconstruct),\n    check: constructFactory(onsuccessfulcheck),\n    interrupt: constructFactory(onsuccessfulcheck, {\n      interrupt: true\n    })\n  }\n  /**\n   * State and tools for resolving and serializing.\n   *\n   * @type {TokenizeContext}\n   */\n\n  const context = {\n    previous: null,\n    code: null,\n    containerState: {},\n    events: [],\n    parser,\n    sliceStream,\n    sliceSerialize,\n    now,\n    defineSkip,\n    write\n  }\n  /**\n   * The state function.\n   *\n   * @type {State|void}\n   */\n\n  let state = initialize.tokenize.call(context, effects)\n  /**\n   * Track which character we expect to be consumed, to catch bugs.\n   *\n   * @type {Code}\n   */\n\n  let expectedCode\n\n  if (initialize.resolveAll) {\n    resolveAllConstructs.push(initialize)\n  }\n\n  return context\n  /** @type {TokenizeContext['write']} */\n\n  function write(slice) {\n    chunks = push(chunks, slice)\n    main() // Exit if we’re not done, resolve might change stuff.\n\n    if (chunks[chunks.length - 1] !== null) {\n      return []\n    }\n\n    addResult(initialize, 0) // Otherwise, resolve, and exit.\n\n    context.events = resolveAll(resolveAllConstructs, context.events, context)\n    return context.events\n  } //\n  // Tools.\n  //\n\n  /** @type {TokenizeContext['sliceSerialize']} */\n\n  function sliceSerialize(token, expandTabs) {\n    return serializeChunks(sliceStream(token), expandTabs)\n  }\n  /** @type {TokenizeContext['sliceStream']} */\n\n  function sliceStream(token) {\n    return sliceChunks(chunks, token)\n  }\n  /** @type {TokenizeContext['now']} */\n\n  function now() {\n    return Object.assign({}, point)\n  }\n  /** @type {TokenizeContext['defineSkip']} */\n\n  function defineSkip(value) {\n    columnStart[value.line] = value.column\n    accountForPotentialSkip()\n  } //\n  // State management.\n  //\n\n  /**\n   * Main loop (note that `_index` and `_bufferIndex` in `point` are modified by\n   * `consume`).\n   * Here is where we walk through the chunks, which either include strings of\n   * several characters, or numerical character codes.\n   * The reason to do this in a loop instead of a call is so the stack can\n   * drain.\n   *\n   * @returns {void}\n   */\n\n  function main() {\n    /** @type {number} */\n    let chunkIndex\n\n    while (point._index < chunks.length) {\n      const chunk = chunks[point._index] // If we’re in a buffer chunk, loop through it.\n\n      if (typeof chunk === 'string') {\n        chunkIndex = point._index\n\n        if (point._bufferIndex < 0) {\n          point._bufferIndex = 0\n        }\n\n        while (\n          point._index === chunkIndex &&\n          point._bufferIndex < chunk.length\n        ) {\n          go(chunk.charCodeAt(point._bufferIndex))\n        }\n      } else {\n        go(chunk)\n      }\n    }\n  }\n  /**\n   * Deal with one code.\n   *\n   * @param {Code} code\n   * @returns {void}\n   */\n\n  function go(code) {\n    consumed = undefined\n    expectedCode = code\n    state = state(code)\n  }\n  /** @type {Effects['consume']} */\n\n  function consume(code) {\n    if (markdownLineEnding(code)) {\n      point.line++\n      point.column = 1\n      point.offset += code === -3 ? 2 : 1\n      accountForPotentialSkip()\n    } else if (code !== -1) {\n      point.column++\n      point.offset++\n    } // Not in a string chunk.\n\n    if (point._bufferIndex < 0) {\n      point._index++\n    } else {\n      point._bufferIndex++ // At end of string chunk.\n      // @ts-expect-error Points w/ non-negative `_bufferIndex` reference\n      // strings.\n\n      if (point._bufferIndex === chunks[point._index].length) {\n        point._bufferIndex = -1\n        point._index++\n      }\n    } // Expose the previous character.\n\n    context.previous = code // Mark as consumed.\n\n    consumed = true\n  }\n  /** @type {Effects['enter']} */\n\n  function enter(type, fields) {\n    /** @type {Token} */\n    // @ts-expect-error Patch instead of assign required fields to help GC.\n    const token = fields || {}\n    token.type = type\n    token.start = now()\n    context.events.push(['enter', token, context])\n    stack.push(token)\n    return token\n  }\n  /** @type {Effects['exit']} */\n\n  function exit(type) {\n    const token = stack.pop()\n    token.end = now()\n    context.events.push(['exit', token, context])\n    return token\n  }\n  /**\n   * Use results.\n   *\n   * @type {ReturnHandle}\n   */\n\n  function onsuccessfulconstruct(construct, info) {\n    addResult(construct, info.from)\n  }\n  /**\n   * Discard results.\n   *\n   * @type {ReturnHandle}\n   */\n\n  function onsuccessfulcheck(_, info) {\n    info.restore()\n  }\n  /**\n   * Factory to attempt/check/interrupt.\n   *\n   * @param {ReturnHandle} onreturn\n   * @param {Record<string, unknown>} [fields]\n   */\n\n  function constructFactory(onreturn, fields) {\n    return hook\n    /**\n     * Handle either an object mapping codes to constructs, a list of\n     * constructs, or a single construct.\n     *\n     * @param {Construct|Construct[]|ConstructRecord} constructs\n     * @param {State} returnState\n     * @param {State} [bogusState]\n     * @returns {State}\n     */\n\n    function hook(constructs, returnState, bogusState) {\n      /** @type {Construct[]} */\n      let listOfConstructs\n      /** @type {number} */\n\n      let constructIndex\n      /** @type {Construct} */\n\n      let currentConstruct\n      /** @type {Info} */\n\n      let info\n      return Array.isArray(constructs)\n        ? /* c8 ignore next 1 */\n          handleListOfConstructs(constructs)\n        : 'tokenize' in constructs // @ts-expect-error Looks like a construct.\n        ? handleListOfConstructs([constructs])\n        : handleMapOfConstructs(constructs)\n      /**\n       * Handle a list of construct.\n       *\n       * @param {ConstructRecord} map\n       * @returns {State}\n       */\n\n      function handleMapOfConstructs(map) {\n        return start\n        /** @type {State} */\n\n        function start(code) {\n          const def = code !== null && map[code]\n          const all = code !== null && map.null\n          const list = [\n            // To do: add more extension tests.\n\n            /* c8 ignore next 2 */\n            ...(Array.isArray(def) ? def : def ? [def] : []),\n            ...(Array.isArray(all) ? all : all ? [all] : [])\n          ]\n          return handleListOfConstructs(list)(code)\n        }\n      }\n      /**\n       * Handle a list of construct.\n       *\n       * @param {Construct[]} list\n       * @returns {State}\n       */\n\n      function handleListOfConstructs(list) {\n        listOfConstructs = list\n        constructIndex = 0\n\n        if (list.length === 0) {\n          return bogusState\n        }\n\n        return handleConstruct(list[constructIndex])\n      }\n      /**\n       * Handle a single construct.\n       *\n       * @param {Construct} construct\n       * @returns {State}\n       */\n\n      function handleConstruct(construct) {\n        return start\n        /** @type {State} */\n\n        function start(code) {\n          // To do: not needed to store if there is no bogus state, probably?\n          // Currently doesn’t work because `inspect` in document does a check\n          // w/o a bogus, which doesn’t make sense. But it does seem to help perf\n          // by not storing.\n          info = store()\n          currentConstruct = construct\n\n          if (!construct.partial) {\n            context.currentConstruct = construct\n          }\n\n          if (\n            construct.name &&\n            context.parser.constructs.disable.null.includes(construct.name)\n          ) {\n            return nok(code)\n          }\n\n          return construct.tokenize.call(\n            // If we do have fields, create an object w/ `context` as its\n            // prototype.\n            // This allows a “live binding”, which is needed for `interrupt`.\n            fields ? Object.assign(Object.create(context), fields) : context,\n            effects,\n            ok,\n            nok\n          )(code)\n        }\n      }\n      /** @type {State} */\n\n      function ok(code) {\n        consumed = true\n        onreturn(currentConstruct, info)\n        return returnState\n      }\n      /** @type {State} */\n\n      function nok(code) {\n        consumed = true\n        info.restore()\n\n        if (++constructIndex < listOfConstructs.length) {\n          return handleConstruct(listOfConstructs[constructIndex])\n        }\n\n        return bogusState\n      }\n    }\n  }\n  /**\n   * @param {Construct} construct\n   * @param {number} from\n   * @returns {void}\n   */\n\n  function addResult(construct, from) {\n    if (construct.resolveAll && !resolveAllConstructs.includes(construct)) {\n      resolveAllConstructs.push(construct)\n    }\n\n    if (construct.resolve) {\n      splice(\n        context.events,\n        from,\n        context.events.length - from,\n        construct.resolve(context.events.slice(from), context)\n      )\n    }\n\n    if (construct.resolveTo) {\n      context.events = construct.resolveTo(context.events, context)\n    }\n  }\n  /**\n   * Store state.\n   *\n   * @returns {Info}\n   */\n\n  function store() {\n    const startPoint = now()\n    const startPrevious = context.previous\n    const startCurrentConstruct = context.currentConstruct\n    const startEventsIndex = context.events.length\n    const startStack = Array.from(stack)\n    return {\n      restore,\n      from: startEventsIndex\n    }\n    /**\n     * Restore state.\n     *\n     * @returns {void}\n     */\n\n    function restore() {\n      point = startPoint\n      context.previous = startPrevious\n      context.currentConstruct = startCurrentConstruct\n      context.events.length = startEventsIndex\n      stack = startStack\n      accountForPotentialSkip()\n    }\n  }\n  /**\n   * Move the current point a bit forward in the line when it’s on a column\n   * skip.\n   *\n   * @returns {void}\n   */\n\n  function accountForPotentialSkip() {\n    if (point.line in columnStart && point.column < 2) {\n      point.column = columnStart[point.line]\n      point.offset += columnStart[point.line] - 1\n    }\n  }\n}\n/**\n * Get the chunks from a slice of chunks in the range of a token.\n *\n * @param {Chunk[]} chunks\n * @param {Pick<Token, 'start'|'end'>} token\n * @returns {Chunk[]}\n */\n\nfunction sliceChunks(chunks, token) {\n  const startIndex = token.start._index\n  const startBufferIndex = token.start._bufferIndex\n  const endIndex = token.end._index\n  const endBufferIndex = token.end._bufferIndex\n  /** @type {Chunk[]} */\n\n  let view\n\n  if (startIndex === endIndex) {\n    // @ts-expect-error `_bufferIndex` is used on string chunks.\n    view = [chunks[startIndex].slice(startBufferIndex, endBufferIndex)]\n  } else {\n    view = chunks.slice(startIndex, endIndex)\n\n    if (startBufferIndex > -1) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view[0] = view[0].slice(startBufferIndex)\n    }\n\n    if (endBufferIndex > 0) {\n      // @ts-expect-error `_bufferIndex` is used on string chunks.\n      view.push(chunks[endIndex].slice(0, endBufferIndex))\n    }\n  }\n\n  return view\n}\n/**\n * Get the string value of a slice of chunks.\n *\n * @param {Chunk[]} chunks\n * @param {boolean} [expandTabs=false]\n * @returns {string}\n */\n\nfunction serializeChunks(chunks, expandTabs) {\n  let index = -1\n  /** @type {string[]} */\n\n  const result = []\n  /** @type {boolean|undefined} */\n\n  let atTab\n\n  while (++index < chunks.length) {\n    const chunk = chunks[index]\n    /** @type {string} */\n\n    let value\n\n    if (typeof chunk === 'string') {\n      value = chunk\n    } else\n      switch (chunk) {\n        case -5: {\n          value = '\\r'\n          break\n        }\n\n        case -4: {\n          value = '\\n'\n          break\n        }\n\n        case -3: {\n          value = '\\r' + '\\n'\n          break\n        }\n\n        case -2: {\n          value = expandTabs ? ' ' : '\\t'\n          break\n        }\n\n        case -1: {\n          if (!expandTabs && atTab) continue\n          value = ' '\n          break\n        }\n\n        default: {\n          // Currently only replacement character.\n          value = String.fromCharCode(chunk)\n        }\n      }\n\n    atTab = chunk === -2\n    result.push(value)\n  }\n\n  return result.join('')\n}\n","/**\n * @typedef {import('micromark-util-types').Extension} Extension\n */\nimport {\n  attention,\n  autolink,\n  blockQuote,\n  characterEscape,\n  characterReference,\n  codeFenced,\n  codeIndented,\n  codeText,\n  definition,\n  hardBreakEscape,\n  headingAtx,\n  htmlFlow,\n  htmlText,\n  labelEnd,\n  labelStartImage,\n  labelStartLink,\n  lineEnding,\n  list,\n  setextUnderline,\n  thematicBreak\n} from 'micromark-core-commonmark'\nimport {resolver as resolveText} from './initialize/text.js'\n/** @type {Extension['document']} */\n\nexport const document = {\n  [42]: list,\n  [43]: list,\n  [45]: list,\n  [48]: list,\n  [49]: list,\n  [50]: list,\n  [51]: list,\n  [52]: list,\n  [53]: list,\n  [54]: list,\n  [55]: list,\n  [56]: list,\n  [57]: list,\n  [62]: blockQuote\n}\n/** @type {Extension['contentInitial']} */\n\nexport const contentInitial = {\n  [91]: definition\n}\n/** @type {Extension['flowInitial']} */\n\nexport const flowInitial = {\n  [-2]: codeIndented,\n  [-1]: codeIndented,\n  [32]: codeIndented\n}\n/** @type {Extension['flow']} */\n\nexport const flow = {\n  [35]: headingAtx,\n  [42]: thematicBreak,\n  [45]: [setextUnderline, thematicBreak],\n  [60]: htmlFlow,\n  [61]: setextUnderline,\n  [95]: thematicBreak,\n  [96]: codeFenced,\n  [126]: codeFenced\n}\n/** @type {Extension['string']} */\n\nexport const string = {\n  [38]: characterReference,\n  [92]: characterEscape\n}\n/** @type {Extension['text']} */\n\nexport const text = {\n  [-5]: lineEnding,\n  [-4]: lineEnding,\n  [-3]: lineEnding,\n  [33]: labelStartImage,\n  [38]: characterReference,\n  [42]: attention,\n  [60]: [autolink, htmlText],\n  [91]: labelStartLink,\n  [92]: [hardBreakEscape, characterEscape],\n  [93]: labelEnd,\n  [95]: attention,\n  [96]: codeText\n}\n/** @type {Extension['insideSpan']} */\n\nexport const insideSpan = {\n  null: [attention, resolveText]\n}\n/** @type {Extension['attentionMarkers']} */\n\nexport const attentionMarkers = {\n  null: [42, 95]\n}\n/** @type {Extension['disable']} */\n\nexport const disable = {\n  null: []\n}\n","/**\n * @typedef {import('micromark-util-types').InitialConstruct} InitialConstruct\n * @typedef {import('micromark-util-types').FullNormalizedExtension} FullNormalizedExtension\n * @typedef {import('micromark-util-types').ParseOptions} ParseOptions\n * @typedef {import('micromark-util-types').ParseContext} ParseContext\n * @typedef {import('micromark-util-types').Create} Create\n */\nimport {combineExtensions} from 'micromark-util-combine-extensions'\nimport {content} from './initialize/content.js'\nimport {document} from './initialize/document.js'\nimport {flow} from './initialize/flow.js'\nimport {text, string} from './initialize/text.js'\nimport {createTokenizer} from './create-tokenizer.js'\nimport * as defaultConstructs from './constructs.js'\n/**\n * @param {ParseOptions} [options]\n * @returns {ParseContext}\n */\n\nexport function parse(options = {}) {\n  /** @type {FullNormalizedExtension} */\n  // @ts-expect-error `defaultConstructs` is full, so the result will be too.\n  const constructs = combineExtensions(\n    // @ts-expect-error Same as above.\n    [defaultConstructs].concat(options.extensions || [])\n  )\n  /** @type {ParseContext} */\n\n  const parser = {\n    defined: [],\n    lazy: {},\n    constructs,\n    content: create(content),\n    document: create(document),\n    flow: create(flow),\n    string: create(string),\n    text: create(text)\n  }\n  return parser\n  /**\n   * @param {InitialConstruct} initial\n   */\n\n  function create(initial) {\n    return creator\n    /** @type {Create} */\n\n    function creator(from) {\n      return createTokenizer(parser, initial, from)\n    }\n  }\n}\n"],"sourceRoot":""}